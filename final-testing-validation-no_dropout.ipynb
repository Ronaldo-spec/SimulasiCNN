{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras import datasets,layers, models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONNECT DENGAN DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"blobs.fit\"\n",
    "latih =  \"latih\"\n",
    "validasi = \"validasi\"\n",
    "testing = \"testing\"\n",
    "!ls \"D:\\TUGAS\\Kuliah\\Semester8\\SourcesCode\\SimulasiCNN\\blobs.fit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bahan_dir = os.path.join(base_dir)\n",
    "train_dir = os.path.join(latih)\n",
    "valid_dir = os.path.join(validasi)\n",
    "test_dir = os.path.join(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradeA_dir = os.path.join(bahan_dir, 'gradeA/')\n",
    "gradeB_dir = os.path.join(bahan_dir, 'gradeB/')\n",
    "gradeC_dir = os.path.join(bahan_dir, 'gradeC/')\n",
    "\n",
    "print(\"Jumlah data tiap kelas\")\n",
    "print(\"Jumlah gambar grade  A : \", len(os.listdir(gradeA_dir)))\n",
    "print(\"Jumlah gambar grade  B : \", len(os.listdir(gradeB_dir)))\n",
    "print(\"Jumlah gambar grade  C : \", len(os.listdir(gradeC_dir)))\n",
    "print(\"Total dataset : \", len(os.listdir(gradeA_dir)) + len(os.listdir(gradeB_dir)) + len(os.listdir(gradeC_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direktori isi latih/training\n",
    "train_gradeA = os.path.join(train_dir, 'gradeA/')\n",
    "train_gradeB = os.path.join(train_dir, 'gradeB/')\n",
    "train_gradeC = os.path.join(train_dir, 'gradeC/')\n",
    "\n",
    "# direktori isi validasi\n",
    "valid_gradeA = os.path.join(valid_dir, 'gradeA/')\n",
    "valid_gradeB = os.path.join(valid_dir, 'gradeB/')\n",
    "valid_gradeC = os.path.join(valid_dir, 'gradeC/')\n",
    "\n",
    "# direktori isi validasi\n",
    "test_gradeA = os.path.join(test_dir, 'gradeA/')\n",
    "test_gradeB = os.path.join(test_dir, 'gradeB/')\n",
    "test_gradeC = os.path.join(test_dir, 'gradeC/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEMBAGI DATASET MENJADI DATA TRAINING DAN DATA VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from shutil import copyfile\n",
    "\n",
    "def train_val_split(source, train, val, test, train_ratio, val_ratio):\n",
    "  total_size = len(os.listdir(source))\n",
    "  train_size = int(train_ratio * total_size)\n",
    "  val_size = int(val_ratio * total_size)\n",
    "  test_size = total_size - train_size - val_size\n",
    "\n",
    "  randomized  = random.sample(os.listdir(source), total_size)\n",
    "  train_files = randomized[0:train_size]\n",
    "  val_files   = randomized[train_size:train_size+val_size]\n",
    "  test_files = randomized[train_size+val_size:total_size]\n",
    "\n",
    "  for i in train_files:\n",
    "    i_file = source + i\n",
    "    destination = train + i\n",
    "    copyfile(i_file, destination)\n",
    "\n",
    "  for i in val_files:\n",
    "    i_file = source + i\n",
    "    destination = val + i\n",
    "    copyfile(i_file, destination)\n",
    "  for i in test_files:\n",
    "    i_file = source + i\n",
    "    destination = test + i\n",
    "    copyfile(i_file, destination)\n",
    "\n",
    "# jumlah pembagian data training dan testing\n",
    "train_ratio = 0.9\n",
    "val_ratio = 0.05\n",
    "\n",
    "#pembagian training dan validasi \n",
    "#gradeA\n",
    "source_00 = gradeA_dir\n",
    "train_00  = train_gradeA\n",
    "val_00    = valid_gradeA\n",
    "test_00   = test_gradeA\n",
    "train_val_split(source_00, train_00, val_00, test_00, train_ratio, val_ratio )\n",
    "\n",
    "#gradeB\n",
    "source_01 = gradeB_dir\n",
    "train_01  = train_gradeB\n",
    "val_01    = valid_gradeB\n",
    "test_01   = test_gradeB\n",
    "train_val_split(source_01, train_01, val_01, test_01, train_ratio, val_ratio )\n",
    "\n",
    "#gradeC\n",
    "source_02 = gradeC_dir\n",
    "train_02  = train_gradeC\n",
    "val_02    = valid_gradeC\n",
    "test_02   = test_gradeC\n",
    "train_val_split(source_02, train_02, val_02, test_02, train_ratio, val_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Jumlah all grade A   : \", len(os.listdir(gradeA_dir)))\n",
    "print(\"Jumlah train grade A : \", len(os.listdir(train_gradeA)))\n",
    "print(\"Jumlah validation grade A   : \", len(os.listdir(valid_gradeA)))\n",
    "print(\"Jumlah testing grade A   : \", len(os.listdir(test_gradeA)))\n",
    "\n",
    "print(\"\\nJumlah all grade B   : \", len(os.listdir(gradeB_dir)))\n",
    "print(\"Jumlah train grade B : \", len(os.listdir(train_gradeB)))\n",
    "print(\"Jumlah validation grade B   : \", len(os.listdir(valid_gradeB)))\n",
    "print(\"Jumlah testing grade B   : \", len(os.listdir(test_gradeB)))\n",
    "\n",
    "print(\"\\nJumlah all grade C   : \", len(os.listdir(gradeC_dir)))\n",
    "print(\"Jumlah train grade C : \", len(os.listdir(train_gradeC)))\n",
    "print(\"Jumlah validation grade C   : \", len(os.listdir(valid_gradeC)))\n",
    "print(\"Jumlah testing grade C   : \", len(os.listdir(test_gradeC)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOBILENET V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen       = ImageDataGenerator(\n",
    "    rescale         = 1./255\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale         = 1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (128,128)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# train_dir = os.path.join(base_dir, 'latih')\n",
    "# validation_dir = os.path.join(base_dir, 'validasi')\n",
    "\n",
    "# train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, class_mode= 'categorical')\n",
    "# validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, class_mode= 'categorical')\n",
    "\n",
    "train_dataset = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = IMG_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle    = False,\n",
    "    class_mode = 'categorical',\n",
    "    color_mode = 'rgb'\n",
    ")\n",
    "valid_dataset = val_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size = IMG_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle    = False,\n",
    "    class_mode = 'categorical',\n",
    "    color_mode = 'rgb'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "MobileNetV2 = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "\n",
    "for layer in MobileNetV2.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UJI COBA CUSTOM MODEL KE-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = MobileNetV2.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "# x = tf.keras.layers.Dropout(0.1)(x)\n",
    "output = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
    "modelku = tf.keras.Model(inputs=MobileNetV2.input, outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelku.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "modelku.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "                loss=\"categorical_crossentropy\",\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = modelku.fit(train_dataset, epochs=10, validation_data=valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelku.save('model/modelku-fit_data-baru_59.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training dan validation accurasi dan loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label = 'Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label = 'Validation Accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menampilkan precission, recall, dan f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluasi model\n",
    "y_true = valid_dataset.classes\n",
    "Y_pred = modelku.predict(valid_dataset, verbose=1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "# Tampilkan laporan klasifikasi\n",
    "target_names = list(valid_dataset.class_indices.keys())\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "class_list = os.listdir(train_dir)\n",
    "\n",
    "# membuat prediksi pada data validasi\n",
    "y_pred = modelku.predict(valid_dataset)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# mengambil label yang sebenarnya\n",
    "y_true = valid_dataset.classes\n",
    "\n",
    "# membuat confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# menampilkan confusion matrix dengan heatmap\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=class_list, yticklabels=class_list)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export TFLITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the Keras model\n",
    "model = tf.keras.models.load_model('model\\modelku-fit.h5')\n",
    "\n",
    "# Convert the Keras model to TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TensorFlow Lite model\n",
    "with open('modelku-fit.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "# # Convert the model\n",
    "# converter = tf.lite.TFLiteConverter.from_saved_model(\"model\\modelku-fit_data-baru_59.h5\") # path to the SavedModel directory\n",
    "# tflite_model = converter.convert()\n",
    "\n",
    "# # Save the model.\n",
    "# with open('export-3_blob-fit_no-dropout_59-quant.tflite', 'wb') as f:\n",
    "#   f.write(tflite_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TES Klasifikasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_list = os.listdir(train_dir)\n",
    "\n",
    "img_path = 'validasi\\GradeB\\imageB_432977.bmp'\n",
    "img = image.load_img(img_path, target_size=(128, 128))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "preds = modelku.predict(x)\n",
    "class_idx = np.argmax(preds[0])\n",
    "class_label = class_list[class_idx]\n",
    "\n",
    "imgplot = plt.imshow(img)\n",
    "plt.title(f'Predicted Class: {class_label}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
